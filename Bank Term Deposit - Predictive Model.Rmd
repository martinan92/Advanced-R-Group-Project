---
title: "Bank Term Deposit - Predictive Model"
author: "O-1 R Masters"
date: "6/3/2019"
output: html_document
---

## 1. Introduction

Once we have understood our dataset through EDA, which can be found in the previous R markdown (Bank Term Deposit - Data Exploration), we proceed to create our predictive model using the following approach:

-Data Preparation: Fixing variable types, balancing the dataset and doing the train/test split <br />
-Baseline model: Evaluating metrics on three different models: Logistic Regression, Random Forest and XGBoost. <br />
-Feature Engineering: Attempting to create new variables to better predict the classes of our target variable. <br />
-Model Selection: Compare the performance on the holdout on all models with the best generated features <br />
-Model Tuning: Perform a grid search to get the best parameters on our selected best model <br />

Now we will explain in detail all the previously mentioned steps. <br />

```{r setup}
source('./load_libraries.R')

raw_bank_train <- fread("Data/BankCamp_train.csv")
raw_bank_test <- fread("Data/BankCamp_test.csv")

```


## 2. SMOTE

As seen during the data exploration stage, the train data set has a relative imbalance with regards to the target variable (with the positive classification being the minority). If models were trained on this data as-is, there would be a greater bias towards the majority class leading to improper predictions (particularly a higher proportion of false negatives). To deal with this, the Synthetic Minority Oversampling Technique ("SMOTE") will be utilized. With the given parameters, 5 examples will be created of each original minority class. 

```{r}
fixed_train_df <- fix_types(create_weekday(raw_bank_train))
train_test <- f_partition(fixed_train_df, test_proportion=0.1, seed=20190603)

train_to_smote <- train_test$train
holdout <- train_test$test

if(file.exists("./Data/smote_train.csv")) {
  print("SMOTE already created, reading from file...")
  smote_train_df <- fread("./Data/smote_train.csv")
  smote_train_df$y <- factor(smote_train_df$y, levels=c("yes", "no"))
} else {
  smote_train_df <- SMOTE(y ~ ., train_to_smote, perc.over = 500)
  fwrite(smote_train_df, file = "Data/smote_train.csv")
}
print(summary(smote_train_df))

```


## 3.  Baselines

For this classification task, logistic regression, the ranger implementation of Random Forest, and XG Boost were attempted. As can be seen, as-is the inclusion of a duration yields good results metrics (particularly sensitivity) at this early stage. However, as this would not realistically be available in production, it will be excluded from the model.

NOTE: Scaling is always applied to the logit regression model (due to the preprocessing requirements of the model) and not to the tree based models as this is not considered necessary.

### 3.1 Logit
```{r, warning=FALSE, message=FALSE}

if(file.exists("./saved_models/logit_baseline_smote.rds")) {
  print("Model already trained, reading from file...")
  logit_baseline_smote <- readRDS("./saved_models/logit_baseline_smote.rds")
} else {
  print("Saved model not found, starting training process...")
  pp <- c(scale_df)
  logit_baseline_smote <- pipeline_casero(smote_train_df, preprocessing=pp, model="glm")
  saveRDS(logit_baseline_smote, "./saved_models/logit_baseline_smote.rds")
}


logit_results <- evaluate_model(model=logit_baseline_smote, holdout=scale_df(holdout), "logit_baseline_smote")

model_results <- setNames(data.table(matrix(nrow = 0, ncol = 15)), names(logit_results))
model_results <- rbind(model_results, logit_results)

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))

```


### 3.2 Random Forest
```{r, message=FALSE, warning=FALSE}
if(file.exists("./saved_models/rf_baseline_smote.rds")) {
  print("Model already trained, reading from file...")
  rf_baseline_smote <- readRDS("./saved_models/rf_baseline_smote.rds")
} else {
  print("Saved model not found, starting training process...")
  tg <- data.table(expand.grid(mtry=15,
                             splitrule='gini',
                             min.node.size=5))

  rf_baseline_smote <- pipeline_casero(smote_train_df, tunegrid=tg)
  saveRDS(rf_baseline_smote, "./saved_models/rf_baseline_smote.rds")
}

model_results <- rbind(model_results, evaluate_model(model=rf_baseline_smote, holdout=holdout, "rf_baseline_smote"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))

```


### 3.3 XG Boost
```{r}
if(file.exists("./saved_models/xgb_baseline_smote.rds")) {
  print("Model already trained, reading from file...")
  xgb_baseline_smote <- readRDS("./saved_models/xgb_baseline_smote.rds")
} else {
  # So many tuning parameters wow
  tg <- data.table(expand.grid(eta=0.4,
                             max_depth='2',
                             nrounds=500,
                             gamma=10,
                             colsample_bytree=0.5,
                             min_child_weight=5,
                             subsample=0.9))

  xgb_baseline_smote <- pipeline_casero(smote_train_df, model="xgbTree", tunegrid=tg)
  saveRDS(xgb_baseline_smote, "./saved_models/xgb_baseline_smote.rds")

}

model_results <- rbind(model_results, evaluate_model(model=xgb_baseline_smote, holdout=holdout, "xgb_baseline_smote"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


## 4. Remove Duration Variable

As previously stated, duration is not something we would have at time of prediction, so using it would be considered cheating. These next steps repeat the above processes but on data generated via SMOTE that excludes the duration feature.

### 4.1 SMOTE
```{r}
fixed_train_df <- fix_types(create_weekday(drop_duration(raw_bank_train)))
train_test <- f_partition(fixed_train_df, test_proportion=0.1, seed=20190603)

train_to_smote <- train_test$train
holdout <- train_test$test
  
if(file.exists("./Data/smote_train_no_duration.csv")) {
  print("SMOTE already created, reading from file...")
  smote_train_df <- fread("./Data/smote_train.csv")
  smote_train_df$y <- factor(smote_train_df$y, levels=c("yes", "no"))
} else {
  smote_train_df <- SMOTE(y ~ ., train_to_smote, perc.over = 500)
  fwrite(smote_train_df, file = "Data/smote_train_no_duration.csv")
}
print(summary(smote_train_df))
```


### 4.2 Baselines

Once again, baseline models are run though this time without the inclusion of the “duration” variable. As can be seen below, the sensitivity metric drops quite drastically with logistic regression having the highest value at this stage. Due to poor performance, the XG Boost will be excluded.

#### 4.2.1 Logit
```{r}
if(file.exists("./saved_models/no_duration/logit_baseline_smote.rds")) {
  print("Model already trained, reading from file...")
  logit_baseline_smote <- readRDS("./saved_models/no_duration/logit_baseline_smote.rds")
} else {
  print("Saved model not found, starting training process...")
  pp <- c(scale_df)
  logit_baseline_smote <- pipeline_casero(smote_train_df, preprocessing=pp, model="glm")
  saveRDS(logit_baseline_smote, "./saved_models/no_duration/logit_baseline_smote.rds")
}


logit_results <- evaluate_model(model=logit_baseline_smote, holdout=scale_df(holdout), "logit_baseline_smote")

model_results <- setNames(data.table(matrix(nrow = 0, ncol = 15)), names(logit_results))
model_results <- rbind(model_results, logit_results)

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))

```


#### 4.2.2 Random Forest
```{r}
if(file.exists("./saved_models/no_duration/rf_baseline_smote.rds")) {
  print("Model already trained, reading from file...")
  rf_baseline_smote <- readRDS("./saved_models/no_duration/rf_baseline_smote.rds")
} else {
  print("Saved model not found, starting training process...")
  tg <- data.table(expand.grid(mtry=15,
                             splitrule='gini',
                             min.node.size=5))

  rf_baseline_smote <- pipeline_casero(smote_train_df, tunegrid=tg)
  saveRDS(rf_baseline_smote, "./saved_models/no_duration/rf_baseline_smote.rds")
}

model_results <- rbind(model_results, evaluate_model(model=rf_baseline_smote, holdout=holdout, "rf_baseline_smote"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))

```


#### 4.2.3 XG Boost
```{r}
if(file.exists("./saved_models/no_duration/xgb_baseline_smote.rds")) {
  print("Model already trained, reading from file...")
  xgb_baseline_smote <- readRDS("./saved_models/no_duration/xgb_baseline_smote.rds")
} else {
  # So many tuning parameters wow
  tg <- data.table(expand.grid(eta=0.4,
                             max_depth='2',
                             nrounds=500,
                             gamma=10,
                             colsample_bytree=0.5,
                             min_child_weight=5,
                             subsample=0.9))

  xgb_baseline_smote <- pipeline_casero(smote_train_df, model="xgbTree", tunegrid=tg)
  saveRDS(xgb_baseline_smote, "./saved_models/no_duration/xgb_baseline_smote.rds")

}

model_results <- rbind(model_results, evaluate_model(model=xgb_baseline_smote, holdout=holdout, "xgb_baseline_smote"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


## 5. Scaling for Tree-Based Models
In this stage, scaling is applied to the data and run using the tree-based models. Although this results in very high sensitivity, this is at the expense of the other metrics which fall drastically. This outcome is due to the models predicting essentially all observations in the positive class (meaning that nearly all positives are correctly identified with nearly all negatives incorrectly identified)


### 5.1 Random Forest
```{r}
if(file.exists("./saved_models/no_duration/rf_scaled.rds")) {
  print("Model already trained, reading from file...")
  rf_scaled <- readRDS("./saved_models/no_duration/rf_scaled.rds")
} else {
  print("Saved model not found, starting training process...")
  
  pp <- c(scale_df)
  
  tg <- data.table(expand.grid(mtry=15,
                             splitrule='gini',
                             min.node.size=5))

  rf_scaled <- pipeline_casero(smote_train_df, preprocessing=pp, tunegrid=tg)
  saveRDS(rf_scaled, "./saved_models/no_duration/rf_scaled.rds")
}

model_results <- rbind(model_results, evaluate_model(model=rf_scaled, holdout=scale_df(holdout), "rf_scaled"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))

```


### 5.2 XG Boost
```{r}
if(file.exists("./saved_models/no_duration/xgb_scaled.rds")) {
  print("Model already trained, reading from file...")
  xgb_scaled <- readRDS("./saved_models/no_duration/xgb_scaled.rds")
} else {
  
  pp <- c(scale_df)
  
  # So many tuning parameters wow
  tg <- data.table(expand.grid(eta=0.4,
                             max_depth='2',
                             nrounds=500,
                             gamma=10,
                             colsample_bytree=0.5,
                             min_child_weight=5,
                             subsample=0.9))

  xgb_scaled <- pipeline_casero(smote_train_df, model="xgbTree", preprocessing=pp, tunegrid=tg)
  saveRDS(xgb_scaled, "./saved_models/no_duration/xgb_scaled.rds")

}

model_results <- rbind(model_results, evaluate_model(model=xgb_scaled, holdout=scale_df(holdout), "xgb_scaled"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


## 6. Feature Engineering
### 6.1 Logit Regression
#### 6.1.1 Drop Day

The first engineered feature attempted was dropping the day column as there was no clear relationship in the data exploration. However, the variable will be included in the final model as removing it worsens performance.
```{r}
if(file.exists("./saved_models/no_duration/logit_drop_day.rds")) {
  print("Model already trained, reading from file...")
  logit_drop_day <- readRDS("./saved_models/no_duration/logit_drop_day.rds")
} else { 
  print("Saved model not found, starting training process...")
  pp <- c(scale_df)
  fs <- c(drop_day)
  logit_drop_day <- pipeline_casero(smote_train_df, preprocessing=pp, selection=fs, model="glm")
  saveRDS(logit_drop_day, "./saved_models/no_duration/logit_drop_day.rds")
}

model_results <- rbind(model_results, evaluate_model(model=logit_drop_day, holdout=scale_df(holdout), "logit_drop_day"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))

```


#### 6.1.2 Drop Pdays
The second engineered feature attempted was dropping the pdays column for similar reasons as dropping the day. As this had a negative effect on the model, this variable will be kept in the model.
```{r}
if(file.exists("./saved_models/no_duration/logit_drop_pdays.rds")) {
  print("Model already trained, reading from file...")
  logit_drop_pdays <- readRDS("./saved_models/no_duration/logit_drop_pdays.rds")
} else { 
  print("Saved model not found, starting training process...")
  pp <- c(scale_df)
  fs <- c(drop_pdays)
  logit_drop_pdays <- pipeline_casero(smote_train_df, preprocessing=pp, selection=fs, model="glm")
  saveRDS(logit_drop_pdays, "./saved_models/no_duration/logit_drop_pdays.rds")
}

model_results <- rbind(model_results,
                       evaluate_model(model=logit_drop_pdays,
                                      holdout=scale_df(holdout),
                                      "logit_drop_pdays"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


#### 6.1.3 Clustering
The third engineered feature will cluster based on customer-related features.
```{r}

clustered <- clustering(df_train=smote_train_df, df_test=holdout, n_clusters=4)

if(file.exists("./saved_models/no_duration/logit_cluster.rds")) {
  print("Model already trained, reading from file...")
  logit_cluster <- readRDS("./saved_models/no_duration/logit_cluster.rds")
} else { 
  print("Saved model not found, starting training process...")
  pp <- c(scale_df)
  
  logit_cluster <- pipeline_casero(clustered$train, preprocessing=pp, model="glm")
  
  saveRDS(logit_cluster, "./saved_models/no_duration/logit_cluster.rds")
}

model_results <- rbind(model_results, evaluate_model(model=logit_cluster,
                                                     holdout=scale_df(clustered$test),
                                                     "logit_cluster"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


#### 6.1.4 Numerical Combinations
The fourth engineered feature attempted was creating a numerical combinations of existing variables. These combinations include the following: <br />

Multiplication Based: <br />
-p_campaign_previous = campaign x previous <br />
-p_balance_campaign = balance x campaign <br />
-p_campaign_age = campaign x age <br />
-p_balance_previous = balance x previous <br />
-p_balance_age = balance x age <br />
-age_previous = age x previous <br />

Addition Based: <br />
-s_campaign_age = campaign + age <br />
-s_campaing_previous = campaign + previous <br />

Non-linear combinations: <br />
-balance_sq = balance x balance <br />
-age_sq = age x age <br />
-age_log = log(age) <br />
-age_sqrt = sqrt(age) <br />
-previous_sq = previous x previous <br />
```{r}
if(file.exists("./saved_models/no_duration/logit_numerical_combination.rds")) {
  print("Model already trained, reading from file...")
  logit_numerical_combination <- readRDS("./saved_models/no_duration/logit_numerical_combination.rds")
} else { 
  print("Saved model not found, starting training process...")
  pp <- c(scale_df)
  fc <- c(num_combinations)
  logit_numerical_combination <- pipeline_casero(smote_train_df, preprocessing=pp, creation=fc, model="glm")
  saveRDS(logit_numerical_combination, "./saved_models/no_duration/logit_numerical_combination.rds")
}

model_results <- rbind(model_results,
                       evaluate_model(model=logit_numerical_combination,
                                      holdout=scale_df(num_combinations(holdout)),
                                      "logit_numerical_combination"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


#### 6.1.5 Clustering and Numerical Combinations
```{r}
# All this is necessary since the function that creates the 
campaign_train <- smote_train_df$campaign
previous_train <- smote_train_df$previous

campaign_holdout <- holdout$campaign
previous_holdout <- holdout$previous

clustered <- clustering(df_train=smote_train_df, df_test=holdout, n_clusters=4)
clustered$train$campaign <- campaign_train
clustered$train$previous <- previous_train
clustered$test$campaign <- campaign_holdout
clustered$test$previous <- previous_holdout

if(file.exists("./saved_models/no_duration/logit_cluster_num_comb.rds")) {
  print("Model already trained, reading from file...")
  logit_cluster_num_comb <- readRDS("./saved_models/no_duration/logit_cluster_num_comb.rds")
} else { 
  print("Saved model not found, starting training process...")
  pp <- c(scale_df)
  fc <- c(num_combinations)
  
  logit_cluster_num_comb <- pipeline_casero(clustered$train, preprocessing=pp, creation=fc, model="glm")
  
  saveRDS(logit_cluster_num_comb, "./saved_models/no_duration/logit_cluster_num_comb.rds")
}

model_results <- rbind(model_results, evaluate_model(model=logit_cluster_num_comb,
                                                     holdout=scale_df(num_combinations(clustered$test)),
                                                     "logit_cluster_num_comb"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


### 6.2 Random Forest
#### 6.2.1 Drop Day

The first engineered feature attempted was dropping the day column as there was no clear relationship in the data exploration. However, the variable will be included in the final model as removing it worsens performance.
```{r}
if(file.exists("./saved_models/no_duration/rf_drop_day.rds")) {
  print("Model already trained, reading from file...")
  rf_drop_day <- readRDS("./saved_models/no_duration/rf_drop_day.rds")
} else {
  print("Saved model not found, starting training process...")
  tg <- data.table(expand.grid(mtry=15,
                             splitrule='gini',
                             min.node.size=5))
  
  fs <- c(drop_day)

  rf_drop_day <- pipeline_casero(smote_train_df, tunegrid=tg, selection=fs)
  saveRDS(rf_drop_day, "./saved_models/no_duration/rf_drop_day.rds")
}

model_results <- rbind(model_results, evaluate_model(model=rf_drop_day, holdout=holdout, "rf_drop_day"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


#### 6.2.2 Drop Pdays
The second engineered feature attempted was dropping the pdays column for similar reasons as dropping the day. As this had a negative effect on the model, this variable will be kept in the model.
```{r}
if(file.exists("./saved_models/no_duration/rf_drop_pdays.rds")) {
  print("Model already trained, reading from file...")
  rf_drop_pdays <- readRDS("./saved_models/no_duration/rf_drop_pdays.rds")
} else {
  print("Saved model not found, starting training process...")
  tg <- data.table(expand.grid(mtry=15,
                             splitrule='gini',
                             min.node.size=5))
  
  fs <- c(drop_pdays)

  rf_drop_pdays <- pipeline_casero(smote_train_df, tunegrid=tg, selection=fs)
  saveRDS(rf_drop_pdays, "./saved_models/no_duration/rf_drop_pdays.rds")
}

model_results <- rbind(model_results, evaluate_model(model=rf_drop_pdays, holdout=holdout, "rf_drop_pdays"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```

#### 6.2.3 Clustering
The third engineered feature will cluster based on customer-related features.
```{r}

clustered <- clustering(df_train=smote_train_df, df_test=holdout, n_clusters=4)

if(file.exists("./saved_models/no_duration/rf_cluster.rds")) {
  print("Model already trained, reading from file...")
  rf_cluster <- readRDS("./saved_models/no_duration/rf_cluster.rds")
} else { 
  print("Saved model not found, starting training process...")
  tg <- data.table(expand.grid(mtry=15,
                             splitrule='gini',
                             min.node.size=5))
  
  
  rf_cluster <- pipeline_casero(clustered$train, tunegrid=tg)
  
  saveRDS(rf_cluster, "./saved_models/no_duration/rf_cluster.rds")
}

model_results <- rbind(model_results, evaluate_model(model=rf_cluster,
                                                     holdout=scale_df(clustered$test),
                                                     "rf_cluster"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


#### 6.2.4 Numerical Combinations
The fourth engineered feature attempted was creating a numerical combinations of existing variables. These combinations are the same as the ones under 6.1.4 for the logistic model.
```{r}
if(file.exists("./saved_models/no_duration/rf_numerical_comb.rds")) {
  print("Model already trained, reading from file...")
  rf_numerical_comb <- readRDS("./saved_models/no_duration/rf_numerical_comb.rds")
} else {
  print("Saved model not found, starting training process...")
  tg <- data.table(expand.grid(mtry=15,
                             splitrule='gini',
                             min.node.size=5))

  fc <- c(num_combinations)

  rf_numerical_comb <- pipeline_casero(smote_train_df, tunegrid=tg, creation=fc)
  saveRDS(rf_numerical_comb, "./saved_models/no_duration/rf_numerical_comb.rds")
}

model_results <- rbind(model_results, evaluate_model(model=rf_numerical_comb, holdout=num_combinations(holdout), "rf_numerical_comb"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


## 6. Hyperparameter Tuning
### 6.1 Random Forest
The hyperparameters to be tuned for the Ranger implementation will be mtry (the number of variables that can split a node), splitrule (using gini [information gain] or extratrees [randomly chosen cut points]), and the minimum node size. As the all of the engineered features individually worsened model performance (and therefore were not attempted in combination), the model will be tuned with the original variables.
```{r}

if(file.exists("./saved_models/no_duration/rf_tuned.rds")) {
  print("Model already trained, reading from file...")
  rf_tuned <- readRDS("./saved_models/no_duration/rf_tuned.rds")
} else {
  print("Saved model not found, starting training process...")
  tg_RF <- data.table(expand.grid(mtry = c(5, 10, 15),
                                splitrule=c("gini", "extratrees"),
                                min.node.size = c(1, 5, 10)))

                    
  rf_tuned <- pipeline_casero(smote_train_df, tunegrid=tg_RF)

  saveRDS(rf_tuned, "./saved_models/no_duration/rf_tuned.rds")
}

model_results <- rbind(model_results, evaluate_model(model=rf_tuned, holdout=holdout, "rf_tuned"))

DT::datatable(model_results, 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```


## 7. Results
All our results are now written into a csv. We can see the superior model was the logit_cluster model with a holdout sensitivity **0.381609195402299** and cross validated sensitivity of **0.569281914893617**. More indepth results can be the seen in the shiny app.
```{r}
fwrite(model_results, "./Data/model_results_no_duration.csv")

DT::datatable(fread("./Data/model_results_no_duration.csv"), 
         extensions = c('FixedColumns',"FixedHeader"),
          options = list(scrollX = TRUE, 
                         paging=TRUE,
                         fixedHeader=TRUE))
```

## 8. Predict on blind Test Set
The the final prediction on the blind Test Set results in approximately a 30/70 split with regards to the target distribution. Normally one might expect to see a similar distribution to the original test set, however given the use of SMOTE to deal with the minority class, relatively low sensitivity in training, among other factors the two distributions would be expected to not quite match.
```{r}
fixed_validation_df <- fix_types(create_weekday(drop_duration(raw_bank_test)))
scaled_validation_df <- scale_df(fixed_validation_df)
clustered_validation_df <- clustering(df_train=smote_train_df, df_test=scaled_validation_df, n_clusters=4)

prediction<-predict(logit_cluster, data = clustered_validation_df, type='raw')
write.csv(prediction, file = "Data/output.csv")

summary(prediction)
```


## 9. Conclusion
To summarize, “duration” variable was removed, because, as already explained, we cannot know the duration of a call before the call happened. We saw that our baseline including this variable performed better than our final model, however, from a business perspective we will not be able to deploy this model in reality thus we remove it taking into account a worse performance of our model. In addition, since we have an unbalanced dataset (with more NOs than Yes in the target variable) we had to oversample the positive label to have a balanced dataset which yields significant improvement in our model. While monitoring and performing cross validation on the train set, the models don’t look bad but let’s not forget that it has synthetic data in it which does not accurately represent reality. So, we created an hold out test set based on our unbalanced dataset which is closer to reality getting new data on a daily basis and we tested the model on it. The model that performed best on this holdout set is the logistic regression model with a sensitivity of 38.2% showing lower sensitivity but more stable and realistic results. We used this model then at the end to make predictions on our blind test set. 